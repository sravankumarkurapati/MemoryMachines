# Backend Data Processor - Robust Log Ingestion System

A scalable, event-driven backend system for ingesting, processing, and storing multi-tenant log data with strict isolation guarantees.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /ingest (JSON/TXT)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Service    â”‚  â† FastAPI (Cloud Run / Local)
â”‚  - Validates     â”‚
â”‚  - Normalizes    â”‚
â”‚  - Queues        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Async Publish
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Message Queue   â”‚  â† Redis (Local) / Pub/Sub (Cloud)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Subscribe
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Service  â”‚  â† Python Worker (Cloud Run / Local)
â”‚  - Process       â”‚
â”‚  - Redact PII    â”‚
â”‚  - Store         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Write with isolation
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Firestore Database      â”‚
â”‚  tenants/                â”‚
â”‚    â”œâ”€ acme/              â”‚
â”‚    â”‚  â””â”€ processed_logs/ â”‚
â”‚    â””â”€ beta/              â”‚
â”‚       â””â”€ processed_logs/ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

- **Multi-Format Ingestion**: Supports JSON and plain text
- **Async Processing**: Non-blocking API with queue-based workers
- **Multi-Tenant Isolation**: Physical data separation at collection level
- **PII Redaction**: Automatic masking of sensitive data
- **Crash Recovery**: At-least-once delivery with idempotency
- **Scalable**: Serverless-ready architecture
- **Local Development**: Full stack runs with Docker Compose

## ğŸš€ Quick Start (Local Development)

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local testing)
- Git

### 1. Clone and Setup

```bash
git clone <your-repo>
cd backend-data-processor

# Copy environment file
cp .env.example .env
```

### 2. Start All Services

```bash
# Start Redis, Firestore Emulator, API, and Worker
docker-compose up -d

# View logs
docker-compose logs -f
```

Services will be available at:
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Redis**: localhost:6379
- **Firestore Emulator**: localhost:8080

### 3. Test the API

**JSON Format:**
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "tenant_id": "acme_corp",
    "log_id": "log_001",
    "text": "User 555-0199 accessed dashboard at 10:00 AM"
  }'
```

**Plain Text Format:**
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: text/plain" \
  -H "X-Tenant-ID: beta_inc" \
  -d "Server error on 192.168.1.1 - contact admin@example.com"
```

Expected Response (202 Accepted):
```json
{
  "status": "accepted",
  "message": "Log queued for processing",
  "log_id": "log_001",
  "tenant_id": "acme_corp",
  "request_id": "uuid-here"
}
```

### 4. Verify Data in Firestore

The worker processes messages asynchronously. After a few seconds, check the Firestore emulator:

```bash
# Connect to Firestore container
docker exec -it log_processor_firestore bash

# Or use the Firestore UI at http://localhost:4000
```

## ğŸ§ª Running Tests

```bash
# Install dependencies
pip install -r requirements.txt

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=api --cov=worker --cov=shared

# Run specific test file
pytest tests/test_api.py -v
```

## ğŸ“Š Project Structure

```
backend-data-processor/
â”œâ”€â”€ api/                    # API service
â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â””â”€â”€ utils.py           # Utilities (PII redaction, etc.)
â”œâ”€â”€ worker/                # Worker service
â”‚   â”œâ”€â”€ processor.py       # Message processor
â”‚   â””â”€â”€ config.py          # Worker config
â”œâ”€â”€ shared/                # Shared components
â”‚   â”œâ”€â”€ message_queue.py   # Queue abstraction
â”‚   â””â”€â”€ database.py        # Database abstraction
â”œâ”€â”€ tests/                 # Test suite
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_worker.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ docker-compose.yml     # Local development stack
â”œâ”€â”€ Dockerfile.api         # API container
â”œâ”€â”€ Dockerfile.worker      # Worker container
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸ”‘ Key Design Decisions

### 1. Multi-Tenancy Strategy
- **Physical Isolation**: Each tenant gets their own sub-collection
- **Path**: `tenants/{tenant_id}/processed_logs/{log_id}`
- **Benefit**: Eliminates possibility of cross-tenant data leaks

### 2. Crash Recovery
- **At-least-once delivery**: Pub/Sub guarantees message delivery
- **Idempotency**: Using `log_id` as document key prevents duplicates
- **Retry Logic**: Failed messages automatically retry with backoff

### 3. Performance Optimization
- **Async API**: Returns 202 immediately, processing happens async
- **Queue Buffering**: Decouples API from worker for independent scaling
- **Connection Pooling**: Reuses database connections

### 4. PII Protection
- Automatic detection and redaction of:
  - Phone numbers
  - Email addresses
  - SSN
  - Credit card numbers
  - IP addresses

## ğŸŒ Environment Variables

| Variable | Description | Local Default | Cloud Default |
|----------|-------------|---------------|---------------|
| `ENVIRONMENT` | Deployment environment | `local` | `production` |
| `QUEUE_TYPE` | Message queue type | `redis` | `pubsub` |
| `DATABASE_TYPE` | Database type | `emulator` | `firestore` |
| `LOG_LEVEL` | Logging level | `INFO` | `INFO` |
| `PROCESSING_TIME_PER_CHAR` | Simulated processing time | `0.05` | `0.05` |

## ğŸ“ˆ Performance Characteristics

### Local Development
- **API Response Time**: < 10ms (202 Accepted)
- **Worker Processing**: 0.05s per character + PII redaction
- **Throughput**: ~100 RPM (limited by single worker)

### Cloud Production (Expected)
- **API Response Time**: < 50ms
- **Throughput**: 1000+ RPM with auto-scaling
- **Worker Auto-scaling**: 0-1000 instances based on queue depth

## ğŸ” Monitoring & Debugging

### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f api
docker-compose logs -f worker
```

### Check Queue Depth
```bash
# Connect to Redis
docker exec -it log_processor_redis redis-cli

# Check queue length
LLEN log-ingestion
```

### Inspect Database
```bash
# The Firestore emulator doesn't have a built-in UI
# Use the Cloud Console locally or check logs
docker-compose logs firestore
```

## ğŸ› ï¸ Development Workflow

### Making Changes

1. **Edit code** in `api/`, `worker/`, or `shared/`
2. **Services auto-reload** (via volume mounts)
3. **Run tests**: `pytest tests/ -v`
4. **Commit changes**: Follow conventional commits

### Adding Dependencies

```bash
# Add to requirements.txt
echo "new-package==1.0.0" >> requirements.txt

# Rebuild containers
docker-compose down
docker-compose build
docker-compose up -d
```

## ğŸ› Troubleshooting

### API not responding
```bash
# Check if container is running
docker-compose ps

# Check logs
docker-compose logs api

# Restart service
docker-compose restart api
```

### Worker not processing
```bash
# Check worker logs
docker-compose logs worker

# Verify Redis connection
docker exec -it log_processor_redis redis-cli ping
```

### Can't connect to Firestore
```bash
# Ensure emulator is running
docker-compose ps firestore

# Check emulator logs
docker-compose logs firestore
```

## ğŸ“ API Documentation

### Endpoints

#### `POST /ingest`
Ingest a log for processing.

**JSON Format:**
```bash
POST /ingest
Content-Type: application/json

{
  "tenant_id": "string",
  "log_id": "string",
  "text": "string"
}
```

**Plain Text Format:**
```bash
POST /ingest
Content-Type: text/plain
X-Tenant-ID: string

<raw text content>
```

**Response (202 Accepted):**
```json
{
  "status": "accepted",
  "message": "Log queued for processing",
  "log_id": "string",
  "tenant_id": "string",
  "request_id": "string"
}
```

#### `GET /health`
Health check endpoint.

#### `GET /readiness`
Readiness check for load balancers.

## ğŸ¯ Next Steps (Phase 2)

Ready to deploy to GCP? See the deployment guide for:
- Setting up GCP project
- Configuring Pub/Sub and Firestore
- Deploying to Cloud Run
- Setting up monitoring

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

**Sravan Kumar Kurapati**
- GitHub: [@your-github]
- LinkedIn: [your-linkedin]

---

**Memory Machines Co-Op Application Project**
Built with â¤ï¸ showcasing 13+ years of enterprise backend engineering experience.